# 001
中文：万字长文带你入门虚假新闻检测
链接：[HERE](https://zhuanlan.zhihu.com/p/451905471)
2021

## 问题与现状
虚假新闻越来越多，人工筛选消耗人力物力；
现在的方法往往关注fully-supervised的方式；
现实世界缺乏针对该领域的标注数据；
现实场景更需要无监督/弱监督的方式。

## 社交新闻分析
社交网络的新闻往往包括*新闻内容*，*社交上下文内容*，以及*外部知识*；
*新闻内容*：文章中所包含的文本信息以及图片视频等多模态信息。
*社交上下文内容*：新闻的发布者，新闻的传播网络，以及其他用户对新闻的评论和转发。
*外部知识*：客观事实知识，通常由知识图谱表示外部知识。

**虚假新闻检测**：给定新闻文章的新闻内容，社交上下文内容，以及外部知识，去判断新闻文章的真假。

有监督方法：
&emsp;1.基于文章内容的有监督方法（其中包括基于文本的检测，基于图片内容的检测，以及基于多模态信息的检测）。
&emsp;2.基于社交上下文的有监督方法（其中包括基于用户可信度的虚假新闻检测和基于传播信息的虚假新闻检测）
&emsp;3.基于外部知识的虚假新闻检测方法以及混合方法（利用以上的多种信息）。
弱监督方法：
&emsp;1.基于文本的弱监督方法。
&emsp;2.基于社交上下文的弱监督方法。
无监督方法。

## 自己想法
虚假新闻任务究其根源是分类任务，但不局限于文本分类，且针对的方向存在不同，有的是由于虚假新闻的前后不一致，有些是直接考虑虚假新闻本身的综合特征，还有些结合时间，用户的特征，外部知识的情况。

# 002
英文：Abstract Meaning Representation for Sembanking
中文：针对Sembanking的抽象语义表示 （AMR）
2013
## 问题与现状
句法树库（Syntactic TreeBank）对NLP产生巨大影响，Penn TreeBank将句子转换成对应的句法树；
NLP任务往往是针对句子解析的副产品来解决的；

## 创新与方法
定义抽象语义表示Abstract Meaning Representation AMR;
希望简单的全句子语义结构的sembank（语义库）可以促进NLP的理解和生成。

## 实验与结论
开发了网络界面的AMR编辑器。它允许用户自己对AMR进行构建，并允许不同用户之间的AMR进行比较。
为了评估注释者之间的一致性，以及自动AMR解析的准确性。开发了smatch度量和相关脚本。

## 自己思考
AMR语义图虽然能够直接表示复杂的语义，但是有个明显的缺点，即仅对英语适用。这使得之前的想法不太好。
但是AMR语义图针对 短文本 + 英语 的环境会比较适用。
AMR语义图十分复杂，但是从某种角度来说，AMR语义图可能更适合做预训练，比起之前的针对句子的半结构化的预训练方式，这种通过语义图的方式更直接表示了词的分布，反应词的深层含义。

## AMR特点
1.AMR是有根，有向，有标签的图，便于人阅读，程序遍历；
2.AMR针对抽象语法特征，相同含义的句子会在同一AMR图中。（“他描述她为天才”、“他对她的描述:天才”、“根据他的描述，她是天才”）
3.AMR使用PropBank框架集。（“invest-01”框架表示像“债券投资者”）
4.AMR不清楚如何从字符串中获得具体含义，反之亦然。当seq2AMR时，不指定规则应用程序的特定序列，或提供反应这种规则的序列对齐。这使得研究人员探索字符串和意义之间的具体关系。
5.AMR严重偏向英语。

# 003
英文：Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection
中文：针对释义检测的动态池化和展开循环自动编码器
2011
## 问题与现状
释义检测任务：检查两个句子意思是否相同。
需要对两个语句进行语法和语义分析。
其实本质是挖掘句子的深层语义特征。

## 创新与方法
基于递归自动编码器的释义检测方法（RAE）。
该方法是无监督的，基于一个新的展开目标学习句法树中的短语的特征向量。
最后通过这些特征来衡量两个句子之间的短语和单词的相似度。
得到的相似度矩阵大小可以随句子长度变化，通过引入新的动态池层实现，它从可变大小的矩阵计算固定大小的表示，之后使用池化表示作为分类器输入。
文本-->解析树-->RAE无监督得到特征矩阵-->动态池层-->固定大小的特征向量
![20221110142715](https://cdn.jsdelivr.net/gh/DrankXs/picrepo/20221110142715.png)
## 实验与结论
在具有挑战性的MSRP转述语料库上优于其他最先进的方法。

## 自己思考
释义检测任务在现在看来，其实是文本相似度的任务，只要能准确表示句向量，这个任务就很简单。
本质是通过解析树来进行预训练的AE，没有用循环神经网络是局限。

# 004*（但不要看）
英文：Top-Down Versus Bottom-Up Control of Attention in the refrontal and Posterior Parietal Cortices 
中文：在前额叶与后顶叶皮层的自顶向下与自底向上控制的注意力
2007
（不是普通论文结构，是science上的医学论文）

## 文章分段介绍
**材料与方法**
通过动物实验。具体不做描述。
神经活动的绝对时间随不同任务和不同统计标准之间不同。所以考虑区域之间的相对时间差异。
**行为任务**
动物实验。具体不做描述
**记录位置**
动物实验。具体不做描述
**单个神经元选择**
关于目标位置的神经信息反映了注意力的分配。
通过互信息两来评估单个单元对目标位置的选择性。（self-attention为何有效）
互信息统计量反映了基于给定神经元的放电速率(LIP和LPFC神经元如图S2所示)预测目标位置的能力。(NLP领域中，对应的就是下游任务所需关注的内容)
神经元的作用表现出来对目标位置的选择性，即对不同位置存在不同的关注程度，就是attention。
**在数组启动和扫视初始化中对齐数据**
实验，pass
**神经活动与行为的相关性**
每个区域的单个神经元活动与动物找到目标的速度相关。
感兴趣的区域直接参与了任务，支持了它们在注意力中的作用。
**相干统计**
实验，pass

## 自己思考
医学论文，很难看懂，主要考虑了attention，可能有用的部分已经在前面描述过了，这表示attention机制是经生物学证明的。令人注意的是该论文在07年发表，其实隐含的表示了self-attention和cross-attention的有效性（互信息评估单个单元对目标位置的选择），但是机器学习上对attention的应用最初是利用线性层来得到的，这是固定规则的，可能是基于经验的描述。之后才逐渐发现self-attention的有效性，而这之间过了近10年。不同学科的扩展是很有必要的。

# 005
英文：SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization
中文：SummaReranker：一种多任务混合专家的抽象摘要重排序框架
2022
## 问题与现状
Seq2Seq神经网络在抽象摘要上取得成功；
通过对下游数据集上的PLM进行微调，再通过beam-search得到多个候选摘要，从而生成唯一摘要。
但是由于搜索空间很大，加上暴露偏差，解码方式并不有效。
beam-search+自回归式解码，难以编码全局约束，如语法性，一致性和事实一致性。
暴露偏差指的是训练时和推断时产生的固有差异，训练时是知道整个结果的，而推断时是不清楚的。
最近的第二阶段摘要法：
RefSum; SimCLS;XSum。
## 创新与方法
证明了直接训练一个第二阶段模型来一组候选摘要对象中重排序是可能的；
mixture-of-experts SummaReranker的作用是能够选出一个更好的候选摘要，从而持续改进基本模型的性能。
SummaReranker

## 实验与结论
base-model：PEGASUS;
评估得分rouge-1，在CNN-DM上提高了5.44%，在XSum上提供的1.31%，在Reddit TIFU上提高了9.34%。

## 自己思考
针对解码的步骤其实还包括最后候选项的选择，更好的选择能更大激发模型的能力；
这里使用专家网络（一个深度模型）来评估不同评价指标的得分，这种方法期望专家网络能够直接评估出candidate的对应得分，而不是最后的硬性计算。
这样的专家网络学习到了评价指标是如和评价的。
同时，多个专家可以综合学习，它学习不同评价指标是如何评价的，多个专家综合判断能够使此学习更加精确。

## Model
### 重排序框架
源文档：$S$
基本模型：$B$
一组解码方法：$\mathbb{D}$
在m个候选摘要$\mathbb{C} = \{C_1, ..., C_m\}$。
评价指标：$\mu$
一组评价指标：$\mathbb{M}$
针对评价指标$\mu$，得到候选摘要的得分集合：$\mathbb{S}_{\mu} = \{\mu{C_1}, ..., \mu(C_m)\}$

则**最后目标**是：
&emsp;训练一个模型$f_{\theta}$，由$\theta$进行参数化，从而选择出在评价指标$\mu$下的最佳摘要$C^*_{\mu}$。
&emsp;$C^*_{\mu} = \underset{C_i\in \mathbb{C}}{argmax} \{\mu(C_1), ..., \mu(C_m)\}$

则视$C_{\mu}^*$为正候选项，其它为负候选项。
则重排序模型$f_{\theta}$在指标$\mu$的情况下，使用二分类交叉熵计算损失。
$\mathcal{L}_{mu} = -y_i log p_{\theta}^{\mu} (C_i) - (1 - y_i) log (1 - p_{\theta}^{\mu}(C_i))$
$y_i = \begin{cases}  1 & \text{if }C_i = C_{\mu}^* \\ 0 & \text{otherwise} \end{cases}$

如果考虑到不同的度量指标,选取n个不同的指标$\mathbb{M} = \{\mu_1, ..., \mu_N\}$,
最终损失为：
$\mathcal{L} = {1 \over N} \underset{\mu \in \mathbb{M}}{\sum}\mathcal{L}_{\mu}$
### 模型架构
![20221111162538](https://cdn.jsdelivr.net/gh/DrankXs/picrepo/20221111162538.png)

第一步，获得候选摘要的良好表示，类似于BERT，构造下述结构，连接源文档和候选摘要：
[CLS] Source [SEP] Candidate
RoBERTa-large作为模型的encoder。
选择encoder之后的[CLS]符作为encoder的最后表示。
之后将[CLS]的表达输入到MLP中，最终会得到一个 Source和 Candidate的联合表示，这里表示为$x$。

在之后使用多任务学习优化指标（ROUGE等指标），采用专家混合体系结构（Mixture-of-experts MoE）,
E个专家：$\mathcal{E_1, ..., E}_E$，后面表示为同架构的MLP层，设置为两个具有ReLU的双层MLP。
N个预测塔：$\mathcal{T_1, ..., T}_N$，最后表示为不同的评价标准，设置为一个单层MLP
在给定输入摘要表示$\boldsymbol{x}$（该$\boldsymbol{x}$为前述的encoder输出，包含src和candidate）的时候，评价标准$\mu$，$k \in \{1, ..., N\}$后，
对输入摘要的预测：
$f_\theta^k(\boldsymbol{x})=\mathcal{T}_k\left(\sum_{i=1}^E \operatorname{softmax}\left(\boldsymbol{W}_k \boldsymbol{x}\right)_{(i)} \mathcal{E}_i(\boldsymbol{x})\right)$
$\boldsymbol{W}_k$是同任务k相关的权重矩阵，
$p^{\mu}_{\theta} = sigmoid(f_{\theta}^k(\boldsymbol{x}))$

模型最后实现为每个任务分配给每个专家不同的权重。

### 解决训练和推理差距
第二阶段学习方法可能会受到固有的分布偏差影响。
为了解决这种偏差：
&emsp;1.将训练集随机切分到相等的两部分，接下来在每个部分进行预训练模型的微调。
&emsp;2.为了为重排序建立一个训练集，我们对未进行训练的一半上的每个模型进行推断。

测试的时候，有两种选择：
基础设置：使用两个base model中的一个，在一半的训练集中训练，再使用重排序器。
转移设置：将SummaReranker应用在base model在整个训练集训练过后的模型。

## 实验
base model： Pegasus
decode 方法： beam-search, diverse beam-search, top-k sampling, top-p sampling。
指标：ROUGE-1, ROUGE-2, ROUGE-L，BERT-SCORE, BARTScore.
数据集：CNN-DM；XSum； Reddit TIFU.










<br><br><br><br><br><br><br><br><br><br><br>