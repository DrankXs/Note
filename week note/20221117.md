# 001
英文：GloVe: Global Vectors for Word Representation
中文：单词表示的全局向量
2014
## 问题与现状
语言语义向量空间模型用实值向量表示每个词。这些向量可以在各种应用中用作特征。
大多数词向量方法依赖词向量对之间的距离或角度；
词类比评估方案检查词向量之间的标量距离，而不是不同维度的差异来捕获对应词的复杂语义；
词向量空间表示方法成功利用向量的运算实现了对语义和句法规律细粒度的捕获，但是这种规律的起源是不透明的。
学习词向量的两个主要模型是：
&emsp;1）全局矩阵分解方法（潜在语义分析LSA）；可以有效利用统计信息，但是在单词类比上差；
&emsp;2）局部上下文窗口方法（skip-gram），在类比上可能好，但是没有很好的利用语料库的统计信息。

## 创新与方法
文章分析确定了在句向量中出现语义和句法规律所需的模型属性。
一个global log-bilinear regression模型结合了 全局矩阵分解 和 局部上下文窗口方法 的优点。
模型只训练一个 word-word 共现矩阵中的非0元素来利用预料中各词的统计信息，而不是训练整个稀疏矩阵或大型语料库中的单个上下文窗口。
该模型生成了一个具有意义的子结构的向量空间。

## 实验与结论
在最近的一个单词类比任务中的表现为75%，在相似性任务和命名实体识别方面也优于相关模型。
在Mikolov上的单词类比任务以及CoNLL-2003共享基准测试集上进行了NER实验。（词相似度和命名实体识别）
数据集：2010Wikipedia；2014WikiPedia；Gigaword5；Gigaword5 + WikiPedia2014；CommonCrawl。

## 自己思考
$F\left(\left(w_i-w_j\right)^T \tilde{w}_k\right)=\frac{P_{i k}}{P_{j k}}$
GloVe的该式很有意思，从某种角度，将其拆分出来，就是计算$\tilde{w}_k$对$w_i$和$w_j$的注意力（Transformer计算注意力的方法），然后相减，得到对应的关注，即后续表示词k对词i和词j的倾向度。
运用数学方式，一步步对词向量的训练方式进行合理推算，考虑了词统计特征的影响，以及针对共现词的逻辑特征处理。

# 002*
英文：OpenPrompt: An Open-source Framework for Prompt-learning
中文：OpenPrompt：一个用于提示学习的开源框架
2022
## 问题与现状
提示学习是目前NLP领域的新范式，它可以直接将预训练模型应用于各种NLP任务；
现在提示学习代码未受一个统一的管理，仅是特定场景下的实现；
提示学习的选择需要考虑模板策略，初始化策略，语言话策略等细节，所以使用提示学习以适用其快速应用面临着障碍。

## 创新与方法
提出OpenPrompt，一个统一的易于使用的工具包，用于在PLM上进行提示学习。
OpenPrompt框架具有效率，模块化和可扩展性。可组合性允许在统一的范式中自由组合不同的PLM，任务格式和提示模块。
用户可以随时部署prompt学习框架，并在不受约束的情况下评估它们在不同NLP任务上的泛化效果。

## 实验与结论
验证任务：
&emsp;条件生成：WebNLG;
&emsp;自然语言理解：GLUE;SuperGLUE;
&emsp;关系抽取：SemEval
&emsp;细粒度实体识别：Few-NERD;
&emsp;文本分类：MNLI;AG's News; DBPedia; IMDB; 
&emsp;知识探究(Knowledge Probing)：LAMA
且这些任务的数据集都已经集成在OpenPrompt里了。

## 自己思考
目前最流行的Prompt的核心在于使用Prompt实现特定PLM中，预训练任务和当前下游任务的逼近，从而充分利用PLM性能。
该文章主要是提供了一个prompt的框架工具，集成了大部分现有的prompt工作。

# 003
英文：Incorporating Copying Mechanism in Sequence-to-Sequence Learning
中文：在Seq2Seq学习中引入复制机制
2016

## 问题与现状
Seq2Seq模式在NLP任务中取得了成功。
人们倾向于在对话中重复实体名称甚至是长短语。

## 创新与方法
将输入序列有选择性的复制到输出序列中。
将复制融入到基于神经网络的Seq2Seq学习中，并提出了一种新的编码-解码器结构的COPYNET模型。
OPYNET可以很好地将解码器中的常规单词生成方式与新的复制机制集成在一起，这种复制机制可以选择输入序列中的子序列，并将它们放在输出序列中的适当位置。

## 实验与结论
对合成数据集和真实世界数据集的实证研究证明了COPYNET的有效性。
规则实验：基于某种规则，设计了数据集
![20221125215417](https://cdn.jsdelivr.net/gh/DrankXs/picrepo/20221125215417.png)
摘要实验：数据集LCSTS
单论对话实验：基于模式匹配的方式从百度贴吧搜集了数据。

## 自己思考
*认为最终的源实例$X$的词为$\mathcal{V} \bigcup UNK \bigcup \mathcal{X}$*
---文章这里可能有些问题，这个应该是输出序列可能含除源$X$外的UNK词，但是输入$X$是不可能包含$X$中不存在的UNK词的。
是从未见过的数据集实验，用于学习语言中的规则，而这规则是自己预设的。
这篇论文用了很多自己设置的数据集，不够典型，但其复制的实现类似于经典的paper PointerNet

# 004
英文：A Neural Attention Model for Sentence Summarization
中文：针对句子摘要的神经注意模型
2015

## 问题与现状
生成式的摘要仍具有挑战性

## 创新与方法
提出了一种完全数据驱动的抽象句子摘要方法。
基于局部注意的模型，该模型根据输入的句子生成摘要中的每个单词。
模型结构简单，但可以很容易地对其进行端到端训练，并扩展到大量的训练数据。

## 实验与结论
在DUC-2004共享任务上的显著性能提升；
使用NLL损失训练

## 自己思考
文章简单的分析了不同Encoder方式中，摘要数学模型的变化。
此前的研究大部分是抽取式的摘要方式，因此这里使用基于注意力的生成式摘要很有新意；
文章没有用循环神经元，但是实现了循环神经网络的效果，使用对应的数学模型，逐字分类。

# 005*
英文：Liquid Time-constant Networks
中文：流体时间常数网络
2022

## 问题与现状
由常微分方程(ODE)确定的连续时间隐藏态的递归神经网络是建模时间序列数据的有效算法。
在目前的形式主义中，神经ode的表达能力如何?我们能否改进它们的结构，使其具有更丰富的表征学习和表达能力?

## 创新与方法
一个新的时间连续循环神经网络模型。
&emsp;不是通过**隐式非线性**来声明学习系统的动力学，而是通过**非线性互联门**来构造**线性一阶动力学系统**的网络。
&emsp;模型表示具有变化的(即液体)时间常数耦合到其隐藏状态的动力系统，其输出由数值微分方程求解器计算，可微，即可应用到神经网络。
&emsp;这种神经网络表现出稳定和有界的行为，在神经常微分方程家族中产生优越的表达能力，并**提高了时间序列预测任务的性能**。

## 实验与结论
首先采用理论方法寻找它们的动力学边界，并在潜在轨迹空间中通过轨迹长度测量计算它们的表达能力。
进行了一系列的时间序列预测实验，以证明液体时间常数网络(LTCs)与经典和现代rnn相比的逼近能力。

## 自己思考
一个新的神经元，通过数学公式和生物学的映射，设计了一个新的循环神经元LTC；
将模型的输出映射在二维空间，绘制图像，图像的长度可以表达不同模型的表现力，文章控制模型规模，从而验证新设计的神经元的高表现力。
模型输出的值有范围，则表示了模型的稳定性，对于我们常见的操作，激活函数就是这个作用。
文章只需要简单证明LTC的有效性，不需要进行复杂的处理，因此我好奇LTC同Transformer架构的PLM的区别，LTC是单纯的普通神经元，类似LSTM，而Transformer以高复杂度，高内存占用实现了高性能。

# 006
英文：Play the Shannon Game With Language Models:A Human-Free Approach to Summary Evaluation
中文：通过语言模型玩香农游戏：一种无人为的摘要评估方法
2022

## 问题与现状
摘要的目的是简明扼要地陈述文档中最重要的信息。
香农游戏是几十年前提出的一种总结质量评分方法，人工利用香农游戏评估耗时耗力。
Rouge要求人类编写参考摘要进行比较，并通过简单的标记重叠来度量摘要质量，忽略了控制人类使用语言的方式的语法和语义。
香农博弈耗时耗力，类似香农博弈的问题博弈和分类博弈往往缺乏泛化性能。

## 创新与方法
引入了新的无引用摘要评估指标，该指标使用预先训练的语言模型来估计文档及其摘要之间共享的信息。
指标是香农游戏(Shannon Game)的现代版本。
将这些指标视为BLANC的延伸，BLANC是一个摘要质量检测方法，它基于语言模型是否对一篇摘要有帮助的准则实现。

## 实验与结论
使用GPT-2，验证了使用的质变和人类的评价是相关的，使用多维度的评判，比如覆盖率，总体质量等五个摘要维度。

## 自己思考
香农博弈是很旧之前就拥有的理论，这里的指标本质上是利用预训练语言模型的丰富知识，让PLM来进行香农游戏，则指标是否准确取决于预训练模型的掌握程度，这是我不太喜欢的，这也是尽管rouge饱受质疑，但仍在摘要领域中作为标准评判指标被使用。
可以探究不同的PLM对指标的影响，以及不同领域该指标是否仍会有用。

## 背景
### 香农游戏
衡量文档和摘要之间的信息保留情况。
最初的时候，通过一个字母一个字母猜测一个文档，之后测量重构文档的猜测总数。
通过将香农博弈转化，变化猜测的元素，可以变成问答游戏/分类游戏。问答游戏猜测不同问题的回答，分类游戏则将文档分为不同的主题。
### 语言模型
泛指预训练语言模型PLM。
### BLANC
一组度量指标，用来度量经过PLM在文档理解任务中，由于访问了摘要获得的性能提升。
使用完型填空任务作为语言理解任务来引入这个概念。
BLANC-help：摘要被放在文档的前面；
BLANC-tune：模型在摘要上微调。

## 方法
**概率上的语言模型表示**
语言模型是文档上的概率分布：对于某些文档D，给出$p(D)$。
PLM通过给定之前的token来预测下一个token：
$p(x_t|x_1, ..., x_{t-1})$
当输入文档为：$\{x_1, ..., x_n\}$
事件E的信息含量/或意外，发生的概率为：$p(E)$，被定义为：$I(E)=-\log p(E)$
把事件E认为是token的出现，就可根据一个LM计算一个文档的信息：
$I(\mathcal{D}) = -\log p(x_1) - \log p(x_2|x_1) -... -\log p(x_n|x_1, x_2, ..., x_{n-1})$

**条件信息**
条件语言模型:$p(\mathcal{D|S})$，表示给定摘要$\mathcal{S}$的条件下，给出文档$\mathcal{D}$的分布。
则可以通过该语言模型计算在已经得到摘要$\mathcal{S}​$的信息的情况下，从文档中$\mathcal{D}​$中得到的信息。
如果摘要$\mathcal{S}$是文档$\mathcal{D}$的有效摘要，则$I(\mathcal{D|S}) <I(\mathcal{D})$
将摘要的质量定义为摘要带来的信息减少(即读原文的时候存在一部分不必再阅读原文的情况)：
$ID(\mathcal{D,S}) = {I(\mathcal{D}) - I(\mathcal{D|S}) \over I(\mathcal{D})}$

将$I(\mathcal{D|D})$视为$I(\mathcal{D|S})$的下界，
$s(\mathcal{D, S}) = {I(\mathcal{D}) - I(\mathcal{D|S}) \over I(\mathcal{D}) - I(\mathcal{D|D})}$

**条件信息逼近**
GPT-2是prompt PLM，通过将摘要$\mathcal{S}$作为prompt，计算生成$\mathcal{D}$

## 实验
PLM：GPT-2 small
比较方法：BLANC（BLANC-help; BLANC-tune）
数据集：CNN/DM
糟糕的摘要：1.所有单词随机打乱；2.其它文档的摘要。
比较了各种指标与单文档摘要覆盖率分数的相关性。
比较了人类评估的整体质量，考虑单个注释者得分与其他注释者平均分之间的平均相关性。
测量了指标的性能，其中摘要在5个不同的维度上进行了评分:流利性、可理解性、信息性、紧凑性和整体质量。







